{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate XGBoost vs LightGBM capabilities:\n",
    "\n",
    "#### This notebook will show how to use the XGBoost GPU accelerated sklearn classification interface along with LightGBM.\n",
    "\n",
    "In this we'll explore:\n",
    "\n",
    "- encoding catagoricals\n",
    "- feature selection\n",
    "- sampling to balance a dataset using over sampling\n",
    "- displaying metrics, roc_auc and confusion matrix to evaluate models\n",
    "- performance of XGB vs LightGBM\n",
    "- comparison between feature importance of XGB and LGBM\n",
    "- performance of Grid Search vs Randomized Search for best hyperparameters\n",
    "- comparison of tuned model to default parameter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    " \n",
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Import sklearn train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Import some sklearn classification metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/EmployeeAttrition.csv')\n",
    "df.Attrition = df.Attrition.eq('No').mul(1)\n",
    "target = 'Attrition'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical columns to one-hot-encoded form (dummies), keep top-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = 7\n",
    "\n",
    "category_df = df.select_dtypes('object')\n",
    "dummy_df = pd.get_dummies(category_df)\n",
    "dummy_df[target] = df[target]\n",
    "\n",
    "# Find correlations with the target\n",
    "most_correlated = dummy_df.corr().abs()[target].sort_values(ascending=False)\n",
    "\n",
    "# Maintain the top-n most correlation features with Grade\n",
    "most_correlated = most_correlated[:features_to_keep]\n",
    "    \n",
    "dummy_df = dummy_df.loc[:, most_correlated.index]\n",
    "most_correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_minority = dummy_df[dummy_df[target]==0]\n",
    "df_majority = dummy_df[dummy_df[target]==1]\n",
    "\n",
    "print(\"minority (0), len:\", len(df_minority), \"majority (0), len:\", len(df_majority))\n",
    " \n",
    "# Downsample majority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority])\n",
    " \n",
    "dummy_df = df_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dummy_df[target]\n",
    "dummy_df = dummy_df.drop(columns = target)\n",
    "\n",
    "\n",
    "# Split into training/testing sets with 20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dummy_df, labels, \n",
    "                                                    test_size = 0.20,\n",
    "                                                    random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts().plot(kind=\"barh\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_train, y_predict_train, \n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    cm = confusion_matrix(y_train, y_predict_train)\n",
    "    classes = set(y_train)\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "def show_metrics(y_test, y_train, y_predict_test, y_predict_train):\n",
    "    # Create table of metric scores\n",
    "    scores = {}\n",
    "    scores['accuracy'] = (accuracy_score(y_test, y_predict_test), \n",
    "                          accuracy_score(y_train, y_predict_train))\n",
    "    scores['roc_auc'] = (roc_auc_score(y_test, y_predict_test), \n",
    "\n",
    "    roc_auc_score(y_train, y_predict_train))\n",
    "\n",
    "    scores_df = pd.DataFrame(scores).transpose()\n",
    "    scores_df.columns = ['Test', 'Train']\n",
    "    scores_df = scores_df[['Train', 'Test']]\n",
    "    scores_df['Test-Train'] = scores_df.Test - scores_df.Train\n",
    "    \n",
    "    plot_confusion_matrix(y_train, y_predict_train)   \n",
    "    \n",
    "    print(\"\\n-----------------------------------------------------\")\n",
    "    print(scores_df)\n",
    "    print(\"\\n-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build XGB (GPU accelerated model, default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_est = xgb.XGBClassifier(tree_method = 'gpu_hist', predictor= 'cpu_predictor', seed=42)\n",
    "\n",
    "\n",
    "xgb_est.fit(X_train, y_train)\n",
    "\n",
    "y_predict_test = xgb_est.predict(X_test)\n",
    "y_predict_train = xgb_est.predict(X_train)\n",
    " \n",
    "show_metrics(y_test, y_train, y_predict_test, y_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Light GBM model (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lgb_est = lgb.LGBMClassifier(seed=42)\n",
    "lgb_est.fit(X_train, y_train)\n",
    "\n",
    "y_predict_test = lgb_est.predict(X_test)\n",
    "y_predict_train = lgb_est.predict(X_train)\n",
    " \n",
    "print(show_metrics(y_test, y_train, y_predict_test, y_predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "xgb.plot_importance(xgb_est, ax=ax[0], max_num_features=None, title=\"XGBoost Feature Importance\")\n",
    "lgb.plot_importance(lgb_est, ax=ax[1], max_num_features=None, title=\"LightGBM Feature Importance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Grid Search to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.001, 0.0025, 0.005],\n",
    "    'n_estimators': [50, 250],\n",
    "    'num_leaves': [6, 12, 16],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 10, 15]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(lgb.LGBMClassifier(seed=42), gridParams, cv=3, verbose=1, n_jobs=8)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_score_, json.dumps(clf.best_params_,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show metrics and CM for best tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = clf.best_estimator_.predict(X_test)\n",
    "y_predict_train = clf.best_estimator_.predict(X_train)\n",
    " \n",
    "print(show_metrics(y_test, y_train, y_predict_test, y_predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "lgb.plot_importance(clf.best_estimator_, ax=ax, max_num_features=None, title=\"LightGBM Feature Importance - GridSearch Tuned model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Random Search to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.001, 0.0025, 0.005],\n",
    "    'n_estimators': stats.randint(50, 1500),\n",
    "    'num_leaves': stats.randint(6, 20),\n",
    "    'min_child_weight': stats.randint(1, 10),\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 10, 15]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(lgb.LGBMClassifier(seed=42), gridParams, cv=3, verbose=1, n_jobs=8)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_score_, json.dumps(clf.best_params_,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics and CM for best tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = clf.best_estimator_.predict(X_test)\n",
    "y_predict_train = clf.best_estimator_.predict(X_train)\n",
    " \n",
    "print(show_metrics(y_test, y_train, y_predict_test, y_predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "lgb.plot_importance(clf.best_estimator_, ax=ax, max_num_features=None, title=\"LightGBM Feature Importance - RandomizedSearchCV Tuned model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
